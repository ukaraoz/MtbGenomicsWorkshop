
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Processing and Merging SNVs from multiple isolates &#8212; M. tuberculosis Bioinformatics Workshop 0.1 documentation</title>
    <link rel="stylesheet" href="../_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="../index.html">M. tuberculosis Bioinformatics Workshop 0.1 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="processing-and-merging-snvs-from-multiple-isolates">
<h1>Processing and Merging SNVs from multiple isolates<a class="headerlink" href="#processing-and-merging-snvs-from-multiple-isolates" title="Permalink to this headline">¶</a></h1>
<p>What we need to do next is to get a set of high-quality <em>SNVs</em> across the whole genome. <code class="docutils literal notranslate"><span class="pre">vcf</span></code> file from <code class="docutils literal notranslate"><span class="pre">Pilon</span></code> contains unfiltered <em>SNVs</em> as well as <em>indels</em>.</p>
<div class="section" id="separating-snvs-and-indels">
<h2>Separating <em>SNVs</em> and <em>indels</em><a class="headerlink" href="#separating-snvs-and-indels" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="filtering-snvs-within-highly-repetitive-regions">
<h2>Filtering <em>SNVs</em> within highly repetitive regions<a class="headerlink" href="#filtering-snvs-within-highly-repetitive-regions" title="Permalink to this headline">¶</a></h2>
<p>A significant portion of the genome of <em>Mycobacterium tuberculosis</em> contains highly repetitive regions. Short-read sequencing isn’t sufficient to make accurate SNV calls within these regions. Therefore we want to remove these regions from further analysis as they will confuse downstream phylogenetic analysis. We have precalculated the repetitive regions, which is provided in the <code class="docutils literal notranslate"><span class="pre">Mtb_repeats.bed</span></code> file in <code class="docutils literal notranslate"><span class="pre">bed</span></code> format. <a class="reference external" href="https://uswest.ensembl.org/info/website/upload/bed.html">bed</a> is a file format used to specify genomic intervals.</p>
<p>Overall, the total length of repetitive regions specified in <code class="docutils literal notranslate"><span class="pre">Mtb_repeats.bed</span></code> is ~572 Kb (~13% of the genome). The majority of these regions (~10% of the genome) belong to two large unrelaed gene families (PE and PPE families) clustered in the genome. They code for glycine-rich proteins that are often based on multiple copies of the polymorphic repetitive sequences referred to as PGRSs <strong>r</strong>e<strong>s</strong>tructured <strong>t</strong>ext. (<a href="#id1"><span class="problematic" id="id2">**</span></a>P**olymorphic guanine cytosine–rich (GC-rich) repetitive sequences) and</p>
<p>572 Mb (~13%)</p>
<p>About 10% of the coding capacity of the genome is devoted to two large unrelated families of acidic, glycine-rich proteins, the PE and PPE families, whose genes are clustered (Figs 1, 2) and are often based on multiple copies of the polymorphic repetitive sequences referred to as PGRSs, and major polymorphic tandem repeats (MPTRs), respectively31,32. The names PE and PPE derive from the motifs Pro – Glu (PE) and Pro – Pro – Glu (PPE) found near the N terminus in most cases33. The 99 members of the PE protein family all have a highly conserved N- terminal domain of  110 amino-acid residues that is predicted to have a globular structure, followed by a C-terminal segment that varies in size, sequence and repeat copy number (Fi</p>
</div>
<div class="section" id="changing-sample-header-in-the-vcf-file">
<h2>Changing sample header in the <code class="docutils literal notranslate"><span class="pre">vcf</span></code> file<a class="headerlink" href="#changing-sample-header-in-the-vcf-file" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="further-snv-filtering">
<h2>Further <em>SNV</em> filtering<a class="headerlink" href="#further-snv-filtering" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="setting-up-an-analysis-directory">
<h2>Setting up an analysis directory<a class="headerlink" href="#setting-up-an-analysis-directory" title="Permalink to this headline">¶</a></h2>
<div class="section" id="copying-and-creating-project-directories-and-files">
<h3>Copying and creating project directories and files<a class="headerlink" href="#copying-and-creating-project-directories-and-files" title="Permalink to this headline">¶</a></h3>
<p>The Snakemake pipline is intended to be run on an input one or more
sequencer bam files, each having a filename represending a sample name.
The output files are named with the same sample names, and are organized
into folders corresponding to the steps of the pipeline in which they
were created.</p>
<p>To get started, create an analysis directory somewhere in your compute
environment to contain the pipeline input and output files.</p>
<p>Into this directory, copy the following file from the <code class="docutils literal notranslate"><span class="pre">viral-ngs/pipes</span></code>
directory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">config</span><span class="o">.</span><span class="n">yaml</span>
<span class="n">Snakefile</span>
</pre></div>
</div>
<p>Since the file <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> is project-specific, you will need to
make changes to it as approprate for your usage. The config file changes
are described in greater detail below.</p>
<p>Next, <code class="docutils literal notranslate"><span class="pre">cd</span></code> to the analysis directory and create symbolic links to the
following:</p>
<ul>
<li><p class="first">The viral-ngs virtual environment:</p>
<p><code class="docutils literal notranslate"><span class="pre">ln</span> <span class="pre">-s</span> <span class="pre">/path/to/venv-viral-ngs</span> <span class="pre">venv</span></code></p>
</li>
<li><p class="first">The viral-ngs project, checked out from GitHub or extracted from a
version-tagged archive:</p>
<p><code class="docutils literal notranslate"><span class="pre">ln</span> <span class="pre">-s</span> <span class="pre">/path/to/viral-ngs</span> <span class="pre">bin</span></code></p>
</li>
</ul>
<p>Within the analysis directory, create the directories and files used by
the Snakemake pipeline:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">/</span>
    <span class="mi">00</span><span class="n">_raw</span><span class="o">/</span>
    <span class="mi">01</span><span class="n">_cleaned</span><span class="o">/</span>
    <span class="mi">01</span><span class="n">_per_sample</span><span class="o">/</span>
    <span class="mi">02</span><span class="n">_align_to_self</span><span class="o">/</span>
    <span class="mi">02</span><span class="n">_assembly</span><span class="o">/</span>
    <span class="mi">03</span><span class="n">_align_to_ref</span><span class="o">/</span>
    <span class="mi">03</span><span class="n">_interhost</span><span class="o">/</span>
    <span class="mi">04</span><span class="n">_intrahost</span><span class="o">/</span>
<span class="n">log</span><span class="o">/</span>
<span class="n">reports</span><span class="o">/</span>
<span class="n">tmp</span><span class="o">/</span>
</pre></div>
</div>
<p>The directory structure created needs to match the locations specified
in <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code>.</p>
</div>
<div class="section" id="adding-input-data">
<h3>Adding input data<a class="headerlink" href="#adding-input-data" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p class="first">Copy each of the raw sample bam files to the <code class="docutils literal notranslate"><span class="pre">00_raw/</span></code> directory
and ensure the file names follow the convention of <code class="docutils literal notranslate"><span class="pre">{sample}.bam</span></code>.</p>
</li>
<li><p class="first">Create a file, <code class="docutils literal notranslate"><span class="pre">samples-depletion.txt</span></code>, to list all of the samples
that should be run through the depletion pipeline, with one
samplename per line as {sample}, following the format of the input
bam file: <code class="docutils literal notranslate"><span class="pre">{sample}.bam</span></code>. For example, if you copied a file called
“G1190.bam” into <code class="docutils literal notranslate"><span class="pre">00_raw/</span></code>, then then <code class="docutils literal notranslate"><span class="pre">samples-depletion.txt</span></code>
would contain the line:</p>
<p><code class="docutils literal notranslate"><span class="pre">G1190</span></code></p>
</li>
<li><p class="first">Create a file, <code class="docutils literal notranslate"><span class="pre">samples-assembly.txt</span></code>, to list all of the samples
that should be run through the assembly pipeline.</p>
</li>
<li><p class="first">Create a file, <code class="docutils literal notranslate"><span class="pre">samples-runs.txt</span></code>, to list all of the samples that
should be run through the int<strong>er</strong>host analysis pipeline.</p>
</li>
<li><p class="first">Create a blank file, <code class="docutils literal notranslate"><span class="pre">samples-assembly-failures.txt</span></code>, that may be
filled in later.</p>
</li>
</ul>
</div>
<div class="section" id="modifying-the-config-yaml-file">
<h3>Modifying the <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> file<a class="headerlink" href="#modifying-the-config-yaml-file" title="Permalink to this headline">¶</a></h3>
<p>Minimal modification to the config file is necessary, though there are a
few things you need to specify:</p>
<p>An email address for when the pipeline fetches reference data from the
NCBI via their <a class="reference external" href="http://www.ncbi.nlm.nih.gov/books/NBK25501/">Entrez
API</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">email_point_of_contact_for_ncbi</span><span class="p">:</span> <span class="s2">&quot;someone@example.com&quot;</span>
</pre></div>
</div>
<p>The path to the depletion databases to be used by BMTagger, along with
the file prefixes of the specific databases to use. The process for
creating BMTagger depletion databases is described in the <a class="reference external" href="ftp://ftp.ncbi.nih.gov/pub/agarwala/bmtagger/README.bmtagger.txt">NIH BMTagger
docs</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bmtagger_db_dir</span><span class="p">:</span> <span class="s2">&quot;/path/to/depletion_databases&quot;</span>
<span class="n">bmtagger_dbs_remove</span><span class="p">:</span>
  <span class="o">-</span> <span class="s2">&quot;hg19&quot;</span>
  <span class="o">-</span> <span class="s2">&quot;GRCh37.68_ncRNA-GRCh37.68_transcripts-HS_rRNA_mitRNA&quot;</span>
  <span class="o">-</span> <span class="s2">&quot;metagenomics_contaminants_v3&quot;</span>
</pre></div>
</div>
<p>Pre-built depletion databases are available in both *.tar.gz and *.lz4
format, for removing human reads and common metagenomic contaminants:</p>
<ul class="simple">
<li><a class="reference external" href="https://storage.googleapis.com/sabeti-public/depletion_dbs/GRCh37.68_ncRNA-GRCh37.68_transcripts-HS_rRNA_mitRNA.tar.gz">GRCh37.68_ncRNA-GRCh37.68_transcripts-HS_rRNA_mitRNA.tar.gz</a> (<a class="reference external" href="https://storage.googleapis.com/sabeti-public/depletion_dbs/GRCh37.68_ncRNA-GRCh37.68_transcripts-HS_rRNA_mitRNA.lz4">*.lz4</a>)</li>
<li><a class="reference external" href="https://storage.googleapis.com/sabeti-public/depletion_dbs/hg19.tar.gz">hg19.tar.gz</a> (<a class="reference external" href="https://storage.googleapis.com/sabeti-public/depletion_dbs/hg19.lz4">*.lz4</a>)</li>
<li><a class="reference external" href="https://storage.googleapis.com/sabeti-public/depletion_dbs/metagenomics_contaminants_v3.tar.gz">metagenomics_contaminants_v3.tar.gz</a> (<a class="reference external" href="https://storage.googleapis.com/sabeti-public/depletion_dbs/metagenomics_contaminants_v3.lz4">*.lz4</a>)</li>
</ul>
<p>Note that these databases must be extracted prior to use.</p>
<p>In addition to the databases used by BMTagger, you will need to specify
the location and file prefix of the BLAST database to be used for
depletion. The process for creating the BLAST database is described in
the <a class="reference external" href="ftp://ftp.ncbi.nih.gov/blast/documents/formatdb.html">NIH BLAST
docs</a>, and on
<a class="reference external" href="http://www.compbio.ox.ac.uk/analysis_tools/BLAST/formatdb.shtml">this
website</a>
from the University of Oxford.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">blast_db_dir</span><span class="p">:</span> <span class="s2">&quot;/path/to/depletion_databases&quot;</span>
<span class="n">blast_db_remove</span><span class="p">:</span> <span class="s2">&quot;metag_v3.ncRNA.mRNA.mitRNA.consensus&quot;</span>
</pre></div>
</div>
<p>A pre-built depletion database is also available for BLAST:</p>
<ul class="simple">
<li><a class="reference external" href="https://storage.googleapis.com/sabeti-public/depletion_dbs/metag_v3.ncRNA.mRNA.mitRNA.consensus.tar.gz">metag_v3.ncRNA.mRNA.mitRNA.consensus.tar.gz</a> (<a class="reference external" href="https://storage.googleapis.com/sabeti-public/depletion_dbs/metag_v3.ncRNA.mRNA.mitRNA.consensus.lz4">*.lz4</a>)</li>
</ul>
<p>Note that this database must be extracted prior to use.</p>
<p>Additional databases are needed to perform metagenomic classification
using <a class="reference external" href="https://ccb.jhu.edu/software/kraken/">Kraken</a>,
<a class="reference external" href="https://github.com/bbuchfink/diamond">Diamond</a>, or
<a class="reference external" href="https://github.com/marbl/Krona/wiki">Krona</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kraken_db</span><span class="p">:</span> <span class="s2">&quot;/path/to/kraken_full_20150910&quot;</span>

<span class="n">diamond_db</span><span class="p">:</span> <span class="s2">&quot;/path/to/diamond_db/nr&quot;</span>

<span class="n">krona_db</span><span class="p">:</span> <span class="s2">&quot;/path/to/krona&quot;</span>
</pre></div>
</div>
<p>Pre-built databases for Kraken, Diamond, and Krona are available:</p>
<ul class="simple">
<li><a class="reference external" href="https://storage.googleapis.com/sabeti-public/meta_dbs/kraken_ercc_db_20160718.tar.gz">kraken_ercc_db_20160718.tar.gz</a> including <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3166838/">ERCC spike-in RNA seqs</a> (<a class="reference external" href="https://storage.googleapis.com/sabeti-public/meta_dbs/kraken_ercc_db_20160718.tar.lz4">*.lz4</a>)</li>
<li><a class="reference external" href="https://storage.googleapis.com/sabeti-public/meta_dbs/kraken_db.tar.gz">kraken_db.tar.gz</a> (<a class="reference external" href="https://storage.googleapis.com/sabeti-public/meta_dbs/kraken_db.tar.lz4">*.lz4</a>)</li>
<li><a class="reference external" href="https://storage.googleapis.com/sabeti-public/meta_dbs/krona_taxonomy_20160502.tar.gz">krona_taxonomy_20160502.tar.gz</a> (<a class="reference external" href="https://storage.googleapis.com/sabeti-public/meta_dbs/krona_taxonomy_20160502.tar.lz4">*.lz4</a>)</li>
<li><a class="reference external" href="https://storage.googleapis.com/sabeti-public/meta_dbs/nr.dmnd.gz">nr.dmnd.gz</a> (<a class="reference external" href="https://storage.googleapis.com/sabeti-public/meta_dbs/nr.dmnd.lz4">*.lz4</a>)</li>
</ul>
<p>Note that these databases must be extracted prior to use.</p>
<p>An array of the <a class="reference external" href="http://www.ncbi.nlm.nih.gov/nuccore/">NCBI GenBank
CoreNucleotide</a> accessions for
the sequences comprising the reference genome to be used for contig
assembly as well as for int<strong>er</strong>host and int<strong>ra</strong>host variant
analysis. In addition, you will need to specify a file prefix to be used
to represent the full reference genome file used downstream.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">accessions_for_ref_genome_build</span><span class="p">:</span>
  <span class="o">-</span> <span class="s2">&quot;KJ660346.2&quot;</span>
</pre></div>
</div>
<p>An optional file containing a list of accessions may be specified for
filtering reads via <a class="reference external" href="http://last.cbrc.jp/doc/lastal.txt">LAST</a>. This is
intended to narrow to a genus. If this file is not provided, viral-ngs
defaults to using the accessions specified for the reference genome.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">accessions_file_for_lastal_db_build</span><span class="p">:</span> <span class="s2">&quot;/path/to/lastal_accessions.txt&quot;</span>
</pre></div>
</div>
<p>A FASTA file to be used by Trimmomatic during assembly to remove
contaminents from reads:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trim_clip_db</span><span class="p">:</span> <span class="s2">&quot;/path/to/depletion_databases/contaminants.fasta&quot;</span>
</pre></div>
</div>
<p>Pre-built databases for Trimmomatic:</p>
<ul class="simple">
<li><a class="reference external" href="https://storage.googleapis.com/sabeti-public/depletion_dbs/contaminants.fasta.tar.gz">contaminants.fasta.tar.gz</a> (<a class="reference external" href="https://storage.googleapis.com/sabeti-public/depletion_dbs/contaminants.fasta.lz4">*.lz4</a>)</li>
</ul>
<p>A FASTA file containing spike-ins to be reported:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">spikeins_db</span><span class="p">:</span> <span class="s2">&quot;/path/to/references/ercc_spike-ins.fasta&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="modifying-the-snakefile">
<h3>Modifying the <code class="docutils literal notranslate"><span class="pre">Snakefile</span></code><a class="headerlink" href="#modifying-the-snakefile" title="Permalink to this headline">¶</a></h3>
<p>Depending on the state of your input data, and where in the pipeline it
may enter, it may be necessary to omit certain processing steps. For
example, if your sequencing center has already demultiplexed your data
and no demultiplexing is needed, you can comment out the following line
in the <code class="docutils literal notranslate"><span class="pre">Snakefile</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">include</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pipesDir</span><span class="p">,</span> <span class="s1">&#39;demux.rules’)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="running-the-pipeline">
<h2>Running the pipeline<a class="headerlink" href="#running-the-pipeline" title="Permalink to this headline">¶</a></h2>
<div class="section" id="configuring-for-your-compute-platform">
<h3>Configuring for your compute platform<a class="headerlink" href="#configuring-for-your-compute-platform" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="running-the-pipeline-directly">
<h3>Running the pipeline directly<a class="headerlink" href="#running-the-pipeline-directly" title="Permalink to this headline">¶</a></h3>
<p>After the above setup is complete, run the pipeline directly by calling
<code class="docutils literal notranslate"><span class="pre">snakemake</span></code> within the analysis directory.</p>
</div>
<div class="section" id="running-the-pipeline-on-gridengine-uger">
<h3>Running the pipeline on GridEngine (UGER)<a class="headerlink" href="#running-the-pipeline-on-gridengine-uger" title="Permalink to this headline">¶</a></h3>
<p>Within <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code>, set the “project” to one that exists on the
cluster system.</p>
<p>Inside the analysis directory, run the job submission command. Ex.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">use</span> <span class="n">UGER</span>
<span class="n">qsub</span> <span class="o">-</span><span class="n">cwd</span> <span class="o">-</span><span class="n">b</span> <span class="n">y</span> <span class="o">-</span><span class="n">q</span> <span class="n">long</span> <span class="o">-</span><span class="n">l</span> <span class="n">m_mem_free</span><span class="o">=</span><span class="mi">4</span><span class="n">G</span> <span class="o">./</span><span class="nb">bin</span><span class="o">/</span><span class="n">pipes</span><span class="o">/</span><span class="n">Broad_UGER</span><span class="o">/</span><span class="n">run</span><span class="o">-</span><span class="n">pipe</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>To kill all jobs that exited (qstat status “Eqw”) with an error:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>qdel $(qstat | grep Eqw | awk &#39;{print $1}&#39;)
</pre></div>
</div>
</div>
<div class="section" id="running-the-pipeline-on-lsf">
<h3>Running the pipeline on LSF<a class="headerlink" href="#running-the-pipeline-on-lsf" title="Permalink to this headline">¶</a></h3>
<p>Inside the analysis directory, run the job submission command. Ex.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bsub</span> <span class="o">-</span><span class="n">o</span> <span class="n">log</span><span class="o">/</span><span class="n">run</span><span class="o">.</span><span class="n">out</span> <span class="o">-</span><span class="n">q</span> <span class="n">forest</span> <span class="o">./</span><span class="nb">bin</span><span class="o">/</span><span class="n">pipes</span><span class="o">/</span><span class="n">Broad_LSF</span><span class="o">/</span><span class="n">run</span><span class="o">-</span><span class="n">pipe</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>If you notice jobs hanging in the <strong>PEND</strong> state, an upstream job may
have failed. Before killing such jobs, verify that the jobs are pending
due to their dependency:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bjobs</span> <span class="o">-</span><span class="n">al</span> <span class="o">|</span> <span class="n">grep</span> <span class="o">-</span><span class="n">A</span> <span class="mi">1</span> <span class="s2">&quot;PENDING REASONS&quot;</span> <span class="o">|</span> <span class="n">grep</span> <span class="o">-</span><span class="n">v</span> <span class="s2">&quot;PENDING REASONS&quot;</span> <span class="o">|</span> <span class="n">grep</span> <span class="o">-</span><span class="n">v</span> <span class="s1">&#39;^--$&#39;</span>
</pre></div>
</div>
<p>To kill all <strong>PEND</strong>ing jobs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>bkill `bjobs | grep PEND | awk &#39;{print $1}&#39;` &gt; /dev/null
</pre></div>
</div>
</div>
<div class="section" id="when-things-go-wrong">
<h3>When things go wrong<a class="headerlink" href="#when-things-go-wrong" title="Permalink to this headline">¶</a></h3>
<p>The pipeline may fail with errors during execution, usually while
generating assemblies with Trinity. If this occurs, examine the output,
add the failing sample names to <code class="docutils literal notranslate"><span class="pre">samples-assembly-failures.txt</span></code>,
keeping the good ones in <code class="docutils literal notranslate"><span class="pre">samples-assembly.txt</span></code>, and re-run the
pipeline. Due to sample degradation prior to sequencing in the wet lab,
not all samples have the integrity to complete the pipeline, and it may
necessary to skip over these samples by adding them to the
<code class="docutils literal notranslate"><span class="pre">samples-assembly-failures.txt</span></code>.</p>
</div>
</div>
<div class="section" id="assembly-of-pre-filtered-reads">
<h2>Assembly of pre-filtered reads<a class="headerlink" href="#assembly-of-pre-filtered-reads" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="taxonomic-filtration-of-raw-reads">
<h2>Taxonomic filtration of raw reads<a class="headerlink" href="#taxonomic-filtration-of-raw-reads" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="starting-from-illumina-bcl-directories">
<h2>Starting from Illumina BCL directories<a class="headerlink" href="#starting-from-illumina-bcl-directories" title="Permalink to this headline">¶</a></h2>
<p>When starting from Illumina run directories, the viral-ngs Snakemake pipeline can demultiplex raw BCL files,
and merge samples from multiple flowcell lanes or libraries. To use viral-ngs in this way, create the following files:</p>
<p><code class="docutils literal notranslate"><span class="pre">flowcells.txt</span></code> (example below): A tab-delimited file describing the flowcells to demultiplex, as well as the lane to use,
a path to the file listing the barcodes used in the lane, the <code class="docutils literal notranslate"><span class="pre">bustard_dir</span></code> (the run directory as written by an Illumina sequencer),
and an optional column for <code class="docutils literal notranslate"><span class="pre">max_mismatches</span></code>, which specifies how many bases are allowed to differ for a read to be assigned to a particular barcode (default: 0). The column <code class="docutils literal notranslate"><span class="pre">max_mismatches</span></code> may be omitted, including its header.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">flowcell</span>        <span class="n">lane</span>    <span class="n">barcode_file</span>    <span class="n">bustard_dir</span>     <span class="n">max_mismatches</span>
<span class="n">H32G3ADXY</span>       <span class="mi">1</span>       <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">barcodes</span><span class="o">.</span><span class="n">txt</span>    <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">illumina</span><span class="o">/</span><span class="n">run</span><span class="o">/</span><span class="n">directory</span><span class="o">/</span><span class="n">run_BH32G3ADXY</span> <span class="mi">1</span>
<span class="n">H32G3ADXY</span>       <span class="mi">2</span>       <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">barcodes</span><span class="o">.</span><span class="n">txt</span>    <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">illumina</span><span class="o">/</span><span class="n">run</span><span class="o">/</span><span class="n">directory</span><span class="o">/</span><span class="n">run_BH32G3ADXY</span> <span class="mi">1</span>
<span class="n">AKJ6R</span>   <span class="mi">1</span>       <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">barcodes</span><span class="o">.</span><span class="n">txt</span>      <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">illumina</span><span class="o">/</span><span class="n">run</span><span class="o">/</span><span class="n">directory</span><span class="o">/</span><span class="n">run_AKJ6R</span>      <span class="mi">1</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">barcodes.txt</span></code> (example below): A tab-delimited file describing the barcodes used for a given sample, along with a library ID.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span>  <span class="n">barcode_1</span>       <span class="n">barcode_2</span>       <span class="n">library_id_per_sample</span>
<span class="mi">41</span><span class="n">C</span>     <span class="n">TAAGGCGA</span>        <span class="n">TATCCTCT</span>        <span class="n">AP2</span>
<span class="mi">21</span><span class="n">P</span>     <span class="n">CGTACTAG</span>        <span class="n">TATCCTCT</span>        <span class="n">AP2</span>
<span class="mi">42</span><span class="n">C</span>     <span class="n">AGGCAGAA</span>        <span class="n">TATCCTCT</span>        <span class="n">AP2</span>
<span class="mi">41</span><span class="n">P</span>     <span class="n">TCCTGAGC</span>        <span class="n">TATCCTCT</span>        <span class="n">AP2</span>
<span class="mi">42</span><span class="n">P</span>     <span class="n">GGACTCCT</span>        <span class="n">TATCCTCT</span>        <span class="n">AP2</span>
<span class="mi">61</span><span class="n">C</span>     <span class="n">TAGGCATG</span>        <span class="n">TATCCTCT</span>        <span class="n">AP2</span>
<span class="mi">61</span><span class="n">P</span>     <span class="n">CTCTCTAC</span>        <span class="n">AGAGTAGA</span>        <span class="n">AP2</span>
<span class="mi">62</span><span class="n">C</span>     <span class="n">CAGAGAGG</span>        <span class="n">AGAGTAGA</span>        <span class="n">AP2</span>
<span class="mi">62</span><span class="n">P</span>     <span class="n">GCTACGCT</span>        <span class="n">AGAGTAGA</span>        <span class="n">AP2</span>
<span class="mi">142</span><span class="n">C</span>    <span class="n">CGAGGCTG</span>        <span class="n">AGAGTAGA</span>        <span class="n">AP2</span>
<span class="n">WATERCTL</span>        <span class="n">AAGAGGCA</span>        <span class="n">AGAGTAGA</span>        <span class="n">AP2</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">samples-depletion.txt</span></code>: the list of sample names to deplete <a class="reference external" href="#adding-input-data">as described above</a>.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Processing and Merging SNVs from multiple isolates</a><ul>
<li><a class="reference internal" href="#separating-snvs-and-indels">Separating <em>SNVs</em> and <em>indels</em></a></li>
<li><a class="reference internal" href="#filtering-snvs-within-highly-repetitive-regions">Filtering <em>SNVs</em> within highly repetitive regions</a></li>
<li><a class="reference internal" href="#changing-sample-header-in-the-vcf-file">Changing sample header in the <code class="docutils literal notranslate"><span class="pre">vcf</span></code> file</a></li>
<li><a class="reference internal" href="#further-snv-filtering">Further <em>SNV</em> filtering</a></li>
<li><a class="reference internal" href="#setting-up-an-analysis-directory">Setting up an analysis directory</a><ul>
<li><a class="reference internal" href="#copying-and-creating-project-directories-and-files">Copying and creating project directories and files</a></li>
<li><a class="reference internal" href="#adding-input-data">Adding input data</a></li>
<li><a class="reference internal" href="#modifying-the-config-yaml-file">Modifying the <code class="docutils literal notranslate"><span class="pre">config.yaml</span></code> file</a></li>
<li><a class="reference internal" href="#modifying-the-snakefile">Modifying the <code class="docutils literal notranslate"><span class="pre">Snakefile</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#running-the-pipeline">Running the pipeline</a><ul>
<li><a class="reference internal" href="#configuring-for-your-compute-platform">Configuring for your compute platform</a></li>
<li><a class="reference internal" href="#running-the-pipeline-directly">Running the pipeline directly</a></li>
<li><a class="reference internal" href="#running-the-pipeline-on-gridengine-uger">Running the pipeline on GridEngine (UGER)</a></li>
<li><a class="reference internal" href="#running-the-pipeline-on-lsf">Running the pipeline on LSF</a></li>
<li><a class="reference internal" href="#when-things-go-wrong">When things go wrong</a></li>
</ul>
</li>
<li><a class="reference internal" href="#assembly-of-pre-filtered-reads">Assembly of pre-filtered reads</a></li>
<li><a class="reference internal" href="#taxonomic-filtration-of-raw-reads">Taxonomic filtration of raw reads</a></li>
<li><a class="reference internal" href="#starting-from-illumina-bcl-directories">Starting from Illumina BCL directories</a></li>
</ul>
</li>
</ul>

  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/day3/merge_snvs_from_vcf.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="../index.html">M. tuberculosis Bioinformatics Workshop 0.1 documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, Ulas Karaoz.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.5.
    </div>
  </body>
</html>